{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trình thu thập tự động feedback của khách hàng \n",
    "\n",
    "---\n",
    "\n",
    "các trang web:\n",
    "\n",
    "Iphone Xmas: asin = B07H5JNWTS\n",
    "\n",
    "Apple iPhone 8 Plus 5.5\", 64 GB, Fully Unlocked, Gold: asin = B075R9PX3V\n",
    "\n",
    "Apple iPhone 8 4.7\", 64 GB, Fully Unlocked, Gold: asin = B075R93J59\n",
    "\n",
    "Apple iPhone 7 Plus Unlocked Phone 32 GB - US Version (Black): asin = B073QMF6Z9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cần cài đặt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Written as part of https://www.scrapehero.com/how-to-scrape-amazon-product-reviews-using-python/\t\t\n",
    "from lxml import html  \n",
    "import json\n",
    "import requests\n",
    "import json,re\n",
    "from dateutil import parser as dateparser\n",
    "from time import sleep\n",
    "\n",
    "#remove stop word\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "# download stopword\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# split() string qith multiple delimiter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParseReviews(asin):\n",
    "    #This script has only been tested with Amazon.com\n",
    "    amazon_url  = 'http://www.amazon.com/dp/'+asin\n",
    "    # Add some recent user agent to prevent amazon from blocking the request \n",
    "    # Find some chrome user agent strings  here https://udger.com/resources/ua-list/browser-detail?browser=Chrome\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'}\n",
    "\n",
    "    for i in range(1):\n",
    "\n",
    "        response = requests.get(amazon_url,headers = headers,verify=False)\n",
    "        if response.status_code==404:\n",
    "            return {\"url\":amazon_url,\"error\":\"page not found\"}\n",
    "        if response.status_code!=200:\n",
    "            continue\n",
    "\n",
    "        '''\n",
    "        The HTML xpath parser from lxml.etree seems to have max depth limit. \n",
    "        It won't traverse further to parse the text if the depth exceeds 254. \n",
    "        To avoid this, splitting the html into chunks\n",
    "        '''\n",
    "        html_chunks = response.text.split('<div id=\"Ask\">')\n",
    "        \n",
    "        data = {}\n",
    "        for chunks in html_chunks:\n",
    "            parser = html.fromstring(chunks)\n",
    "            XPATH_AGGREGATE = '//span[@id=\"acrCustomerReviewText\"]'\n",
    "            XPATH_REVIEW_SECTION_1 = '//div[contains(@id,\"reviews-summary\")]'\n",
    "            XPATH_REVIEW_SECTION_2 = '//div[@data-hook=\"review\"]'\n",
    "\n",
    "            XPATH_AGGREGATE_RATING = '//table[@id=\"histogramTable\"]//tr'\n",
    "            XPATH_PRODUCT_NAME = '//h1//span[@id=\"productTitle\"]//text()'\n",
    "            XPATH_PRODUCT_PRICE  = '//span[@id=\"priceblock_ourprice\"]/text()'\n",
    "\n",
    "            raw_product_price = parser.xpath(XPATH_PRODUCT_PRICE)\n",
    "            raw_product_name = parser.xpath(XPATH_PRODUCT_NAME)\n",
    "\n",
    "            product_price = ''.join(raw_product_price).replace(',','')\n",
    "            product_name = ''.join(raw_product_name).strip()\n",
    "\n",
    "            data.update({\"name\":product_name}) if product_name else data.get(\"name\")\n",
    "            data.update({\"price\":product_price}) if product_price else data.get(\"price\")\n",
    "\n",
    "            total_ratings  = parser.xpath(XPATH_AGGREGATE_RATING)\n",
    "            reviews = parser.xpath(XPATH_REVIEW_SECTION_1)\n",
    "            \n",
    "            \n",
    "            if not reviews:\n",
    "                reviews = parser.xpath(XPATH_REVIEW_SECTION_2)\n",
    "            ratings_dict = {}\n",
    "            reviews_list = []        \n",
    "\n",
    "            #grabing the rating  section in product page\n",
    "            for ratings in total_ratings:\n",
    "                extracted_rating = ratings.xpath('./td//a//text()')\n",
    "                if extracted_rating:\n",
    "                    rating_key = extracted_rating[0] \n",
    "                    raw_raing_value = extracted_rating[1]\n",
    "                    rating_value = raw_raing_value\n",
    "                    if rating_key:\n",
    "                        ratings_dict.update({rating_key:rating_value})\n",
    "\n",
    "            #Parsing individual reviews\n",
    "            for review in reviews:\n",
    "                XPATH_RATING  = './/i[@data-hook=\"review-star-rating\"]//text()'\n",
    "                XPATH_REVIEW_HEADER = './/a[@data-hook=\"review-title\"]//text()'\n",
    "                XPATH_REVIEW_POSTED_DATE = './/span[@data-hook=\"review-date\"]//text()'\n",
    "                XPATH_REVIEW_TEXT_1 = './/div[@data-hook=\"review-collapsed\"]//text()'\n",
    "                XPATH_REVIEW_TEXT_2 = './/div//span[@data-action=\"columnbalancing-showfullreview\"]/@data-columnbalancing-showfullreview'\n",
    "                XPATH_REVIEW_COMMENTS = './/span[@data-hook=\"review-comment\"]//text()'\n",
    "                XPATH_AUTHOR  = './/span[contains(@class,\"profile-name\")]//text()'\n",
    "                XPATH_REVIEW_TEXT_3  = './/div[contains(@id,\"dpReviews\")]/div/text()'\n",
    "                \n",
    "\n",
    "                raw_review_author = review.xpath(XPATH_AUTHOR)\n",
    "                raw_review_rating = review.xpath(XPATH_RATING)\n",
    "                raw_review_header = review.xpath(XPATH_REVIEW_HEADER)\n",
    "                raw_review_posted_date = review.xpath(XPATH_REVIEW_POSTED_DATE)\n",
    "                raw_review_text1 = review.xpath(XPATH_REVIEW_TEXT_1)\n",
    "                raw_review_text2 = review.xpath(XPATH_REVIEW_TEXT_2)\n",
    "                raw_review_text3 = review.xpath(XPATH_REVIEW_TEXT_3)\n",
    "\n",
    "                #cleaning data\n",
    "                author = ' '.join(' '.join(raw_review_author).split())\n",
    "                review_rating = ''.join(raw_review_rating).replace('out of 5 stars','')\n",
    "                review_header = ' '.join(' '.join(raw_review_header).split())\n",
    "\n",
    "                try:\n",
    "                    review_posted_date = dateparser.parse(''.join(raw_review_posted_date)).strftime('%d %b %Y')\n",
    "                except:\n",
    "                    review_posted_date = None\n",
    "                review_text = ' '.join(' '.join(raw_review_text1).split())\n",
    "\n",
    "                #grabbing hidden comments if present\n",
    "                if raw_review_text2:\n",
    "                    json_loaded_review_data = json.loads(raw_review_text2[0])\n",
    "                    json_loaded_review_data_text = json_loaded_review_data['rest']\n",
    "                    cleaned_json_loaded_review_data_text = re.sub('<.*?>','',json_loaded_review_data_text)\n",
    "                    full_review_text = review_text+cleaned_json_loaded_review_data_text\n",
    "                else:\n",
    "                    full_review_text = review_text\n",
    "                if not raw_review_text1:\n",
    "                    full_review_text = ' '.join(' '.join(raw_review_text3).split())\n",
    "\n",
    "                raw_review_comments = review.xpath(XPATH_REVIEW_COMMENTS)\n",
    "                review_comments = ''.join(raw_review_comments)\n",
    "                review_comments = re.sub('[A-Za-z]','',review_comments).strip()\n",
    "                review_dict = {\n",
    "                                    'review_comment_count':review_comments,\n",
    "                                    'review_text':full_review_text,\n",
    "                                    'review_posted_date':review_posted_date,\n",
    "                                    'review_header':review_header,\n",
    "                                    'review_rating':review_rating,\n",
    "                                    'review_author':author\n",
    "\n",
    "                                }\n",
    "                reviews_list.append(review_dict)\n",
    "\n",
    "            data.update({\n",
    "                        'ratings':ratings_dict,\n",
    "                        'reviews':reviews_list,\n",
    "                        'url':amazon_url,\n",
    "                    })\n",
    "        return data\n",
    "    return {\"error\":\"failed to process the page\",\"url\":amazon_url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadAsin():\n",
    "    #Add your own ASINs here \n",
    "    AsinList = ['B075QN8NDH']\n",
    "    extracted_data = []\n",
    "    for asin in AsinList:\n",
    "        print(\"Downloading and processing page http://www.amazon.com/dp/\"+asin)\n",
    "        extracted_data.append(ParseReviews(asin))\n",
    "        sleep(5)\n",
    "    f = open('data.json','w')\n",
    "    json.dump(extracted_data,f,indent=4,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWord(review):\n",
    "    # khởi tạo 1 set stop word\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    # tách câu thành tokens  \n",
    "    word_tokens = word_tokenize(review)\n",
    "    # tra từng tokens trong set stopword và lưu phần còn lại vào lại câu\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "    # trả về\n",
    "    re_review = ' '.join(filtered_sentence)\n",
    "    return re_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentenceExtract(paragraph):\n",
    "    #sen = re.split('. |! |? |; ', paragraph)\n",
    "    sen = re.split('; |\\. |\\? |\\! ',a)\n",
    "    return sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcReviews(filename):\n",
    "    # doc file va load du lieu\n",
    "    f = open(filename,'r')\n",
    "    data_jsons = json.loads(f.read())\n",
    "    f.close()\n",
    "    \n",
    "    # xu li tung review\n",
    "    for i_data in range(len(data_jsons)):\n",
    "        for i_review in range(len((data_jsons[i_data])['reviews'])):\n",
    "            print((((data_jsons[i_data])['reviews'])[i_review])['review_text'])\n",
    "            # tiến hành tách câu và gán lại cho biến review_texr\n",
    "            (((data_jsons[i_data])['reviews'])[i_review])['review_text'] = sentenceExtract((((data_jsons[i_data])['reviews'])[i_review])['review_text'])\n",
    "            # tiến hành tách stopword\n",
    "            #for sentence in review['review_text']:\n",
    "                \n",
    "    print(data_jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and processing page http://www.amazon.com/dp/B075QN8NDH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Apple iPhone X, Fully Unlocked 5.8\", 64 GB - Silver', 'ratings': {'5 star': '59%', '4 star': '5%', '3 star': '3%', '2 star': '3%', '1 star': '30%'}, 'reviews': [{'review_comment_count': '', 'review_text': ['truong ngoc tai', 'dep trai nhat viet nam', 'Co ai dam len tieng', 'muahahahaha.'], 'review_posted_date': '05 Jun 2018', 'review_header': 'My phone came all good but after few months of use', 'review_rating': '1.0 ', 'review_author': 'Amazon Customer'}, {'review_comment_count': '', 'review_text': ['truong ngoc tai', 'dep trai nhat viet nam', 'Co ai dam len tieng', 'muahahahaha.'], 'review_posted_date': '10 Jul 2018', 'review_header': 'Seller is a piece of garbage', 'review_rating': '1.0 ', 'review_author': 'Tim Moore'}, {'review_comment_count': '', 'review_text': ['truong ngoc tai', 'dep trai nhat viet nam', 'Co ai dam len tieng', 'muahahahaha.'], 'review_posted_date': '09 Jun 2018', 'review_header': 'One Star', 'review_rating': '1.0 ', 'review_author': 'NAME_NOT_RETURNED'}, {'review_comment_count': '', 'review_text': ['truong ngoc tai', 'dep trai nhat viet nam', 'Co ai dam len tieng', 'muahahahaha.'], 'review_posted_date': '23 Mar 2018', 'review_header': 'Don’t like when people are not truthful', 'review_rating': '1.0 ', 'review_author': 'Irina'}, {'review_comment_count': '', 'review_text': ['truong ngoc tai', 'dep trai nhat viet nam', 'Co ai dam len tieng', 'muahahahaha.'], 'review_posted_date': '07 Aug 2018', 'review_header': 'Locked', 'review_rating': '1.0 ', 'review_author': 'Dileep kumar patel'}, {'review_comment_count': '', 'review_text': ['truong ngoc tai', 'dep trai nhat viet nam', 'Co ai dam len tieng', 'muahahahaha.'], 'review_posted_date': '28 Aug 2018', 'review_header': 'PHONE IS NOT UNBLOCKED AS ANNOUNCED', 'review_rating': '1.0 ', 'review_author': 'Lais Melo'}, {'review_comment_count': '', 'review_text': ['truong ngoc tai', 'dep trai nhat viet nam', 'Co ai dam len tieng', 'muahahahaha.'], 'review_posted_date': '11 Sep 2018', 'review_header': 'Bad', 'review_rating': '1.0 ', 'review_author': 'Rony'}, {'review_comment_count': '', 'review_text': ['truong ngoc tai', 'dep trai nhat viet nam', 'Co ai dam len tieng', 'muahahahaha.'], 'review_posted_date': '28 Mar 2018', 'review_header': 'Verizon SIM card Damage LCD!', 'review_rating': '1.0 ', 'review_author': 'Jay'}], 'url': 'http://www.amazon.com/dp/B075QN8NDH'}]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    ReadAsin()\n",
    "    preProcReviews('data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
